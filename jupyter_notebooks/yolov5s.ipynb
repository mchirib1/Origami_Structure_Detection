{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AFM_YOLOv5s_notebook_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDqsWUK6k69e"
      },
      "source": [
        "Here we outline the process of using the YOLOv5 code in google collab. Very simple!!  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loPVjwm7lh2K"
      },
      "source": [
        "# **Introduction and Setup**\n",
        "### Here we outline the process for using the YOLOv5 Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysKh8OO2lHHp"
      },
      "source": [
        "First mount the Gdrive to the Google Collab session in order to save results. Next the necessary code is imported from the Ultralytics YOLOv5 repository.\n",
        "\n",
        "The repository can be found here: https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b03f9f0-ae17-4c7d-9a18-459882b7e7e3"
      },
      "source": [
        "# Mount google drive for saving the results\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b115036-4d87-49db-cf36-e0f1d76da51d"
      },
      "source": [
        "# Clone in YOLOv5 repo from ultralytics\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd /content\n",
        "\n",
        "!pip install -r yolov5/requirements.txt  # install dependencies\n",
        "%cd yolov5\n",
        "\n",
        "\n",
        "from datetime import date\n",
        "today = date.today().strftime('%Y%m%d')\n",
        "import torch\n",
        "print('Setup complete on %s. Using torch %s %s' % (today, torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 4462 (delta 5), reused 10 (delta 3), pack-reused 4447\u001b[K\n",
            "Receiving objects: 100% (4462/4462), 7.40 MiB | 31.06 MiB/s, done.\n",
            "Resolving deltas: 100% (3030/3030), done.\n",
            "/content\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 4)) (0.29.21)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 6)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 8)) (7.0.0)\n",
            "Collecting PyYAML>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: tensorboard>=2.2 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 11)) (2.4.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 12)) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 13)) (0.8.1+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 14)) (4.41.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 20)) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 21)) (1.1.5)\n",
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.6/dist-packages (from -r yolov5/requirements.txt (line 30)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.32.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (51.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 12)) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 12)) (0.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r yolov5/requirements.txt (line 21)) (2018.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2->-r yolov5/requirements.txt (line 11)) (0.4.8)\n",
            "Installing collected packages: PyYAML, thop\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 thop-0.0.31.post2005241907\n",
            "/content/yolov5\n",
            "Setup complete on 20210127. Using torch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huLkQXnopKFT"
      },
      "source": [
        "# **Upload Custom Data**\n",
        "\n",
        "Next we create directories to upload the training validation and test sets also their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgIpSN-lchiw",
        "outputId": "d9fb4939-7fe7-4c40-ddef-09d0e889f9ee"
      },
      "source": [
        "# make train, validation, and testing directories to upload images and labels\n",
        "\n",
        "%cd /content\n",
        "%mkdir /content/train\n",
        "%mkdir /content/train/images  \n",
        "%mkdir /content/train/labels\n",
        "\n",
        "%mkdir /content/valid\n",
        "%mkdir /content/valid/images\n",
        "%mkdir /content/valid/labels\n",
        "\n",
        "%mkdir /content/test\n",
        "%mkdir /content/test/images\n",
        "\n",
        "print('Directories created.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Directories created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8yB07h1pzia"
      },
      "source": [
        "# **.yaml File Configuration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k32Y-3w_l3mW"
      },
      "source": [
        "The yaml file is a simple configuration file. It allows the YOLOv5 code to know the path to your training and validation data.  The number of detection classes and what the class names are. \n",
        "\n",
        "In our case all of the detections are on single classes i.e. triangle or rectangle. \n",
        "\n",
        "YAML files are very easy to write in a simple text editor, or using python. Below we provide an example using python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX1lPR90mbBI",
        "outputId": "b49caf56-b2dd-4559-962e-99d34273b5be"
      },
      "source": [
        "# Writing an example YAML file for Triangles.\n",
        "%cd /content\n",
        "with open('data.yaml', 'w') as outfile:\n",
        "  \n",
        "  outfile.write('train: ../train/images\\n') # path from /yolov5/train.py to directory with uploaded training data \n",
        "  outfile.write('val: ../valid/images\\n') # path from /yolov5/train.py to directory with validation data\n",
        "  \n",
        "  outfile.write('\\n')\n",
        "\n",
        "  outfile.write('nc: 1\\n')\n",
        "  outfile.write(\"names: ['Rec']\\n\") ### edit accordingly to the structure or object\n",
        "\n",
        "print('Yaml file written.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Yaml file written.\n",
            "20210126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3DmmGQztJj",
        "outputId": "32458af5-195c-4d07-bf72-cf95c1293b4a"
      },
      "source": [
        "# check yaml datafile \n",
        "# if uploading one either rename or adjust namespace accordingly\n",
        "%cd /content\n",
        "%cat data.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Rec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocZRlyApqQks"
      },
      "source": [
        "# **Review Input Data**\n",
        "\n",
        "Here we review all the data which has been uploaded to ensure we have the correct information for training.  This will also help to estimate batch sizing, training time, etc..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263cf892-f62a-4980-f70e-88cd52b97e99"
      },
      "source": [
        "%cd /content\n",
        "# view the breakdown of the images that you have for training and testing\n",
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
        "print(\"There is n = %s classes in this data set\" %num_classes)\n",
        "print('---------------------------------------------------------------')\n",
        "\n",
        "# prints the number of trining images\n",
        "train_imgs = sorted(os.listdir('/content/train/images'))\n",
        "print('There are %i images ready for training' % len(train_imgs))\n",
        "for img in sorted(train_imgs):\n",
        "  print(img)\n",
        "print('---------------------------------------------------------------')\n",
        "\n",
        "# prints the number of validation images\n",
        "train_imgs = sorted(os.listdir('/content/valid/images'))\n",
        "print('There are %i images ready for validation' % len(train_imgs))\n",
        "for img in sorted(train_imgs):\n",
        "  print(img)\n",
        "print('---------------------------------------------------------------')\n",
        "\n",
        "# prints the number of test images ready for detection\n",
        "test_imgs = sorted(os.listdir('/content/test/images'))\n",
        "print('There are %i images ready for detection' %len(test_imgs))\n",
        "for img in sorted(test_imgs):\n",
        "  print(img)\n",
        "print('---------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "There is n = 1 classes in this data set\n",
            "---------------------------------------------------------------\n",
            "There are 100 images ready for training\n",
            "alpha3_beta10_rectangle_1_r104.png\n",
            "alpha3_beta10_rectangle_1_r105.png\n",
            "alpha3_beta10_rectangle_1_r179.png\n",
            "alpha3_beta10_rectangle_1_r313.png\n",
            "alpha3_beta10_rectangle_1_r334.png\n",
            "alpha3_beta10_rectangle_2_r243.png\n",
            "alpha3_beta10_rectangle_2_r257.png\n",
            "alpha3_beta10_rectangle_2_r272.png\n",
            "alpha3_beta10_rectangle_2_r284.png\n",
            "alpha3_beta10_rectangle_2_r95.png\n",
            "alpha3_beta10_rectangle_3_r135.png\n",
            "alpha3_beta10_rectangle_3_r235.png\n",
            "alpha3_beta10_rectangle_3_r285.png\n",
            "alpha3_beta10_rectangle_3_r29.png\n",
            "alpha3_beta10_rectangle_3_r43.png\n",
            "alpha3_beta10_rectangle_4_r10.png\n",
            "alpha3_beta10_rectangle_4_r177.png\n",
            "alpha3_beta10_rectangle_4_r179.png\n",
            "alpha3_beta10_rectangle_4_r250.png\n",
            "alpha3_beta10_rectangle_4_r75.png\n",
            "alpha3_beta10_rectangle_5_r262.png\n",
            "alpha3_beta10_rectangle_5_r273.png\n",
            "alpha3_beta10_rectangle_5_r292.png\n",
            "alpha3_beta10_rectangle_5_r5.png\n",
            "alpha3_beta10_rectangle_5_r51.png\n",
            "alphaLocon_beta50_rectangle_1_r198.png\n",
            "alphaLocon_beta50_rectangle_1_r217.png\n",
            "alphaLocon_beta50_rectangle_1_r360.png\n",
            "alphaLocon_beta50_rectangle_1_r39.png\n",
            "alphaLocon_beta50_rectangle_1_r90.png\n",
            "alphaLocon_beta50_rectangle_2_r134.png\n",
            "alphaLocon_beta50_rectangle_2_r149.png\n",
            "alphaLocon_beta50_rectangle_2_r241.png\n",
            "alphaLocon_beta50_rectangle_2_r293.png\n",
            "alphaLocon_beta50_rectangle_2_r83.png\n",
            "alphaLocon_beta50_rectangle_3_r30.png\n",
            "alphaLocon_beta50_rectangle_3_r303.png\n",
            "alphaLocon_beta50_rectangle_3_r311.png\n",
            "alphaLocon_beta50_rectangle_3_r343.png\n",
            "alphaLocon_beta50_rectangle_3_r350.png\n",
            "alphaLocon_beta50_rectangle_4_r16.png\n",
            "alphaLocon_beta50_rectangle_4_r242.png\n",
            "alphaLocon_beta50_rectangle_4_r25.png\n",
            "alphaLocon_beta50_rectangle_4_r340.png\n",
            "alphaLocon_beta50_rectangle_4_r98.png\n",
            "alphaLocon_beta50_rectangle_5_r157.png\n",
            "alphaLocon_beta50_rectangle_5_r209.png\n",
            "alphaLocon_beta50_rectangle_5_r353.png\n",
            "alphaLocon_beta50_rectangle_5_r44.png\n",
            "alphaLocon_beta50_rectangle_5_r6.png\n",
            "gray_rectangle_1_r111.png\n",
            "gray_rectangle_1_r176.png\n",
            "gray_rectangle_1_r181.png\n",
            "gray_rectangle_1_r231.png\n",
            "gray_rectangle_1_r43.png\n",
            "gray_rectangle_2_r250.png\n",
            "gray_rectangle_2_r255.png\n",
            "gray_rectangle_2_r307.png\n",
            "gray_rectangle_2_r48.png\n",
            "gray_rectangle_2_r90.png\n",
            "gray_rectangle_3_r156.png\n",
            "gray_rectangle_3_r22.png\n",
            "gray_rectangle_3_r225.png\n",
            "gray_rectangle_3_r249.png\n",
            "gray_rectangle_3_r32.png\n",
            "gray_rectangle_4_r174.png\n",
            "gray_rectangle_4_r21.png\n",
            "gray_rectangle_4_r288.png\n",
            "gray_rectangle_4_r344.png\n",
            "gray_rectangle_4_r74.png\n",
            "gray_rectangle_5_r119.png\n",
            "gray_rectangle_5_r148.png\n",
            "gray_rectangle_5_r193.png\n",
            "gray_rectangle_5_r244.png\n",
            "gray_rectangle_5_r359.png\n",
            "rectangle_1_r100.png\n",
            "rectangle_1_r127.png\n",
            "rectangle_1_r146.png\n",
            "rectangle_1_r149.png\n",
            "rectangle_1_r264.png\n",
            "rectangle_2_r140.png\n",
            "rectangle_2_r150.png\n",
            "rectangle_2_r180.png\n",
            "rectangle_2_r206.png\n",
            "rectangle_2_r93.png\n",
            "rectangle_3_r169.png\n",
            "rectangle_3_r208.png\n",
            "rectangle_3_r296.png\n",
            "rectangle_3_r73.png\n",
            "rectangle_3_r94.png\n",
            "rectangle_4_r134.png\n",
            "rectangle_4_r172.png\n",
            "rectangle_4_r26.png\n",
            "rectangle_4_r305.png\n",
            "rectangle_4_r84.png\n",
            "rectangle_5_r161.png\n",
            "rectangle_5_r302.png\n",
            "rectangle_5_r311.png\n",
            "rectangle_5_r328.png\n",
            "rectangle_5_r349.png\n",
            "---------------------------------------------------------------\n",
            "There are 20 images ready for validation\n",
            "alpha3_beta10_rectangle_1.png\n",
            "alpha3_beta10_rectangle_2.png\n",
            "alpha3_beta10_rectangle_3.png\n",
            "alpha3_beta10_rectangle_4.png\n",
            "alpha3_beta10_rectangle_5.png\n",
            "alphaLocon_beta50_rectangle_1.png\n",
            "alphaLocon_beta50_rectangle_2.png\n",
            "alphaLocon_beta50_rectangle_3.png\n",
            "alphaLocon_beta50_rectangle_4.png\n",
            "alphaLocon_beta50_rectangle_5.png\n",
            "gray_rectangle_1.png\n",
            "gray_rectangle_2.png\n",
            "gray_rectangle_3.png\n",
            "gray_rectangle_4.png\n",
            "gray_rectangle_5.png\n",
            "rectangle_1.png\n",
            "rectangle_2.png\n",
            "rectangle_3.png\n",
            "rectangle_4.png\n",
            "rectangle_5.png\n",
            "---------------------------------------------------------------\n",
            "There are 38 images ready for detection\n",
            "2020-09-16_Mixed-sample-standard-0000.png\n",
            "2020-09-16_Mixed-sample-standard-0001.png\n",
            "2020-09-16_Mixed-sample-standard-0002.png\n",
            "2020-09-16_Mixed-sample-standard-0003.png\n",
            "2020-09-16_Mixed-sample-w-negative-standard-0000.png\n",
            "2020-09-16_Mixed-sample-w-negative-standard-0001.png\n",
            "2020-09-16_Mixed-sample-w-negative-standard-0002.png\n",
            "2020-09-16_Mixed-sample-w-negative-standard-0003.png\n",
            "2020-09-16_Rectangle-standard-0002.png\n",
            "2020-09-16_Rectangle-standard-0003.png\n",
            "2020-09-16_Rectangle-standard-0004.png\n",
            "2020-09-16_Rectangle-standard-0005.png\n",
            "2020-09-16_Triangle-standard-0000.png\n",
            "2020-09-16_Triangle-standard-0001.png\n",
            "2020-09-16_Triangle-standard-0002.png\n",
            "2020-09-16_Triangle-standard-0003.png\n",
            "3quad_test_rectangle_1.png\n",
            "3quad_test_rectangle_2.png\n",
            "3quad_test_rectangle_3.png\n",
            "3quad_test_rectangle_4.png\n",
            "3quad_test_rectangle_5.png\n",
            "3quad_test_triangle_1.png\n",
            "3quad_test_triangle_2.png\n",
            "3quad_test_triangle_3.png\n",
            "3quad_test_triangle_4.png\n",
            "3quad_test_triangle_5.png\n",
            "Error-signal_2020-09-16_Mixed-sample-w-negative-standard-0000.png\n",
            "Lock-in-amplitude_2020-09-16_Mixed-sample-w-negative-standard-0000.png\n",
            "test_rectangle_1.jpg\n",
            "test_rectangle_2.jpg\n",
            "test_rectangle_3.jpg\n",
            "test_rectangle_4.jpg\n",
            "test_rectangle_5.jpg\n",
            "test_triangle_1.png\n",
            "test_triangle_2.png\n",
            "test_triangle_3.png\n",
            "test_triangle_4.png\n",
            "test_triangle_5.png\n",
            "---------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tGAEM4jrAeI"
      },
      "source": [
        "# **Define the model configuration**\n",
        "\n",
        "Here is where you can define or write a custom model or use the YOLOv5 default models.\n",
        "\n",
        "There are 4 different default models which can be found in the /yolov5/models  directory:\n",
        "\n",
        "1. Yolov5s\n",
        "2. Yolov5m\n",
        "3. Yolov5l\n",
        "4. Yolov5x\n",
        "\n",
        "Each model's performance based on benchmark datasets, can be reviewed in the ultralytics yolov5 repository. Generally speaking they trade speed for accuracy with Yolov5s being the fastest and Yolov5x being the slowest.\n",
        "\n",
        "Here we utilize the Yolov5s for our experiments.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDxebz13RdRA",
        "outputId": "4b8fb19a-f50b-42e0-d35b-773c3e1ca29e"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "%cat yolov5/models/yolov5s.yaml # prints the model output for reference"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "# parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "\n",
            "# anchors\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 9, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
            "   [-1, 3, C3, [1024, False]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-AapZo0uDsh"
      },
      "source": [
        "# **Train the Network**\n",
        "\n",
        "Here is where we imput our training and validation data into the Yolov5s framework. \n",
        "\n",
        "Default parameters can be viewed in the /yolov5/train.py file. \n",
        "\n",
        "Some changes we made were:\n",
        "\n",
        "* Adjusting batch size to 10 in order to fit cache into GPU memory.\n",
        "* Training on 1280 images. (default is 960 and image size should remain a multiple of 32).\n",
        "* Ran for 500 epochs \n",
        "* Run with multi-scale\n",
        "\n",
        "The weights are stored according to the `--name` argument as a pytorch file (.pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "#### TRAINING STEP, TIME CONSUMING ####\n",
        "%%time \n",
        "%cd /content/yolov5/\n",
        "\n",
        "import time\n",
        "start = time.time() # Record training time\n",
        "\n",
        "#Parameters can be changed here or in command below\n",
        "model = 'full_rectangle'\n",
        "batch_size = 10\n",
        "image_size = 1280\n",
        "epochs = 1000\n",
        "\n",
        "#The name by which the data will be saved into yolov5 directory\n",
        "name = f'{today}_{model}_{image_size}_{epochs}'\n",
        "\n",
        "# weights and trainign data are stored in the appropriate subdirectory in the /content/yolov5/runs directory\n",
        "!python train.py --name {name} --batch 10 --img-size 1280 --epochs 1000 --data '../data.yaml' --cfg ./models/yolov5s.yaml --weights ''  --cache | tee {name}_train_log.txt\n",
        "\n",
        "fin = time.time()- start\n",
        "hrs = fin*(1/60)**2\n",
        "\n",
        "# Store the training time in a separate file.\n",
        "with open(f'{name}_train_time.txt', 'w') as outfile:\n",
        "  print(f'Training completed in {hrs:0.3f} hours',file=outfile)\n",
        "  print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'),file=outfile)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5WYG8wtv_fW"
      },
      "source": [
        "# **Test Set Detection**\n",
        "\n",
        "Here we run the detection algorithm. Default parameters can be viewed in the /yolov5/train.py file. \n",
        "\n",
        "Some changes we made were:\n",
        "* IoU threshold increased to 0.5\n",
        "* Confidence threshold increased to 0.8\n",
        "* Image size the same as training i.e. 1280  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49cb4553-5770-4d02-97ea-0e580411303a"
      },
      "source": [
        "#### Detection Step ####\n",
        "\n",
        "\n",
        "# detection data is stored in the appropriate subdirectory in the /content/yolov5/runs directory\n",
        "%cd /content/yolov5\n",
        "\n",
        "#Parameters can be changed here or in command below\n",
        "model = 'full_triangle'\n",
        "image_size = 1280\n",
        "iou = 0.5\n",
        "confidence = 0.8\n",
        "\n",
        "#The name by which the data will be saved into yolov5 directory\n",
        "name = f'{today}_{model}_{image_size}'\n",
        "\n",
        "#Execute the detection script\n",
        "!python detect.py --name {name} --weights /content/yolov5/weights/best.pt --save-txt --img {image_size} --iou {iou} --conf {confidence} --source ../test/images | tee {name}_detect_results.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "YOLOv5 v4.0-49-gf59f801 torch 1.7.0+cu101 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPS\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.8, device='', exist_ok=False, img_size=1280, iou_thres=0.5, name='20210127_full_triangle_1280', project='runs/detect', save_conf=False, save_txt=True, source='../test/images', update=False, view_img=False, weights=['/content/yolov5/weights/best.pt'])\n",
            "Fusing layers... \n",
            "image 1/10 /content/test/images/triangle_1.png: 1120x1280 31 Tris, Done. (0.048s)\n",
            "image 2/10 /content/test/images/triangle_10.png: 1120x1280 79 Tris, Done. (0.019s)\n",
            "image 3/10 /content/test/images/triangle_2.png: 1056x1280 147 Tris, Done. (0.020s)\n",
            "image 4/10 /content/test/images/triangle_3.png: 1056x1280 143 Tris, Done. (0.019s)\n",
            "image 5/10 /content/test/images/triangle_4.png: 1120x1280 35 Tris, Done. (0.020s)\n",
            "image 6/10 /content/test/images/triangle_5.png: 1056x1280 102 Tris, Done. (0.020s)\n",
            "image 7/10 /content/test/images/triangle_6.png: 1120x1280 32 Tris, Done. (0.020s)\n",
            "image 8/10 /content/test/images/triangle_7.png: 1056x1280 127 Tris, Done. (0.021s)\n",
            "image 9/10 /content/test/images/triangle_8.png: 1120x1280 70 Tris, Done. (0.020s)\n",
            "image 10/10 /content/test/images/triangle_9.png: 1120x1280 53 Tris, Done. (0.019s)\n",
            "Results saved to runs/detect/20210127_full_triangle_1280\n",
            "10 labels saved to runs/detect/20210127_full_triangle_1280/labels\n",
            "Done. (4.233s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slym491DylWl"
      },
      "source": [
        "# **Save Results to Google Drive** \n",
        "*Only available if the google drive mount key was used in the first code segment* \n",
        "\n",
        "This code segement saves the copies the current yolov5 directory into google drive. \n",
        "\n",
        "!!Caution data will be overwritten!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x_wg3VeiXMW",
        "outputId": "ce05391f-884c-4185-9ebc-5775f1925130"
      },
      "source": [
        "# predictions are found under the output folder and weights are stored in the pytorch file (\".pt\")\n",
        "%cp  -r /content/yolov5 /content/gdrive/My\\ Drive \n",
        "\n",
        "print(\"Copied to google drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copied to google drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLA4QGIZzRnQ"
      },
      "source": [
        "# **Clear Completed Data**\n",
        "\n",
        "This code segment programatically clears the run, training, validation, and testing data that currently resides in the collab session.  \n",
        "\n",
        "It will leave the Gdrive untouched!\n",
        "\n",
        "*Caution before clearing run data as it holds weights and detection results*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68A8_gzdnOFZ"
      },
      "source": [
        "# uncomment these to clear the directories and upload new images and lables\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "\n",
        "os.chdir('/content/yolov5/runs')  \n",
        "for dir in os.listdir(): #### make sure data is saved before it is erased!!\n",
        "  shutil.rmtree(dir)     #### this code block removes previous training and detection runs \n",
        "\n",
        "os.chdir('/content/train/images/')\n",
        "for file in os.listdir():\n",
        "  os.remove(file)\n",
        "\n",
        "os.chdir('/content/train/labels')\n",
        "for file in os.listdir():\n",
        "  os.remove(file)\n",
        "\n",
        "os.chdir('/content/valid/labels')\n",
        "for file in os.listdir():\n",
        "  os.remove(file)\n",
        "\n",
        "os.chdir('/content/valid/images')\n",
        "for file in os.listdir():\n",
        "  os.remove(file)\n",
        "\n",
        "os.chdir('/content/test/images')\n",
        "for file in sorted(os.listdir()):\n",
        "  os.remove(file)\n",
        "\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}